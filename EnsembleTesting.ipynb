{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "##################################\n",
    "## Model Parameters\n",
    "##################################\n",
    "\n",
    "remove_label_outliers = False\n",
    "impute_strategy = 'mean'\n",
    "scaling_method = 'standard'\n",
    "do_linear_models = True\n",
    "do_ensemble_models = True\n",
    "cross_validation_k_folds = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml import Workspace\n",
    "ws = Workspace(\n",
    "    workspace_id='bbc0f7b3b64843179da5e569144550aa',\n",
    "    authorization_token='iNjA9YbRxZiG/fAqpTWW6qprqTldqAkTGbvnuGX3yMjrgEzgpNHY4bkHhAZ/x7xvixWPG9i6SdC77Vk35+CFrw==',\n",
    "    endpoint='https://europewest.studioapi.azureml.net'\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "ds = ws.datasets['train_values.csv']\n",
    "X = ds.to_dataframe()\n",
    "\n",
    "ds = ws.datasets['train_labels.csv']\n",
    "Y = ds.to_dataframe()\n",
    "\n",
    "ds = ws.datasets['test_values.csv']\n",
    "X_score = ds.to_dataframe()\n",
    "\n",
    "X = X.set_index('row_id')\n",
    "Y = Y.set_index('row_id')\n",
    "X_score = X_score.set_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training dataset shape:\n",
      "17107 rows, 297 features\n",
      "Fixed categories!\n",
      "New number of features 380 \n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## Remove features\n",
    "##################################\n",
    "def removeFeatures(x):\n",
    "    return x\n",
    "\n",
    "X = removeFeatures(X)\n",
    "X_score = removeFeatures(X_score)\n",
    "\n",
    "##################################\n",
    "## Fixing categorical data\n",
    "##################################\n",
    "\n",
    "print ('\\nTraining dataset shape:\\n%d rows, %d features' %(X.shape[0], X.shape[1]))\n",
    "\n",
    "def OneHotEncode(x):\n",
    "    categorical = x.select_dtypes(exclude=[np.number])\n",
    "    return pd.get_dummies(x, columns=categorical.columns)\n",
    "\n",
    "def makeCategorical(x, feature, value_list):\n",
    "    x[feature] = x[feature].astype(\"category\", categories = value_list)\n",
    "    return x\n",
    "\n",
    "def fixCategoricalData(df):\n",
    "    df = makeCategorical(df, 'school__degrees_awarded_highest', [\"Non-degree-granting\", \"Certificate degree\", \"Associate degree\", \"Bachelor's degree\", \"Graduate degree\"])\n",
    "    df = makeCategorical(df, 'school__degrees_awarded_predominant', [\"Not classified\", \"Predominantly certificate-degree granting\", \"Predominantly associate's-degree granting\", \"Predominantly bachelor's-degree granting\", \"Entirely graduate-degree granting\"])\n",
    "    df = makeCategorical(df, 'school__institutional_characteristics_level', [\"2-year\", \"4-year\", \"Less-than-2-year\"])\n",
    "    df = makeCategorical(df, 'school__ownership', [\"Public\", \"Private for-profit\", \"Private nonprofit\"])\n",
    "    df = makeCategorical(df, 'school__region_id', [\"Plains (IA, KS, MN, MO, NE, ND, SD)\", \"New England (CT, ME, MA, NH, RI, VT)\", \"Southeast (AL, AR, FL, GA, KY, LA, MS, NC, SC, TN, VA, WV)\", \"Mid East (DE, DC, MD, NJ, NY, PA)\", \"Great Lakes (IL, IN, MI, OH, WI)\", \"Far West (AK, CA, HI, NV, OR, WA)\", \"Southwest (AZ, NM, OK, TX)\", \"Rocky Mountains (CO, ID, MT, UT, WY)\", \"Outlying Areas (AS, FM, GU, MH, MP, PR, PW, VI)\"])\n",
    "    df = makeCategorical(df, 'school__state', [\"axc\", \"fga\", \"oly\", \"dmg\", \"hbt\", \"jgn\", \"kll\", \"xve\", \"dfy\", \"oon\", \"oli\", \"iqy\", \"qim\", \"shi\", \"ccg\", \"dkf\", \"ipu\", \"tbs\", \"luw\", \"pxv\", \"hww\", \"lff\", \"slp\", \"wjh\", \"idw\", \"ezv\", \"vvi\", \"zdl\", \"jsu\", \"hks\", \"bww\", \"fxt\", \"rxy\", \"cfi\", \"rse\", \"kus\", \"oub\", \"uah\", \"rya\", \"eyi\", \"wto\", \"gkt\", \"bkc\", \"znt\", \"slo\", \"hqy\", \"rgs\", \"cmz\", \"kdg\", \"pdh\", \"ahh\", \"twr\", \"xws\", \"por\", \"uuo\", \"nhl\", \"hmr\", \"jfm\"])\n",
    "    df = makeCategorical(df, 'school__main_campus', [\"Main campus\", \"Not main campus\"])\n",
    "    df = makeCategorical(df, 'school__online_only', [\"Not distance-education only\", \"nan\", \"Distance-education only\"])\n",
    "    return df\n",
    "\n",
    "X = fixCategoricalData(X)\n",
    "X_score = fixCategoricalData(X_score)\n",
    "\n",
    "X = OneHotEncode(X)\n",
    "X_score = OneHotEncode(X_score)\n",
    "\n",
    "print ('Fixed categories!\\nNew number of features %d ' % X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## Handling Outliers\n",
    "##################################\n",
    "def DetectOutliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 2)\n",
    "    upper_bound = q3 + (iqr * 2)\n",
    "    indices = x[(x > upper_bound) | (x < lower_bound)].index\n",
    "    return indices\n",
    "\n",
    "def RemoveOutliers(x, indexes):\n",
    "    return x.drop(indexes, axis=0)\n",
    "\n",
    "if (remove_label_outliers):\n",
    "    outliers = DetectOutliers(Y['income'])\n",
    "    print ('\\nFound %d outliers for income:\\n' % len(outliers))\n",
    "    print ('Original statistics\\n', Y['income'].describe())\n",
    "    X = RemoveOutliers(X, outliers)\n",
    "    Y = RemoveOutliers(Y, outliers)\n",
    "\n",
    "    print ('\\nRemoving values:\\nNew observation count: ', X.shape[0])\n",
    "    print ('Original statistics\\n', Y['income'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixing missing values:\n",
      "Found 287 features with missing value:\n",
      "\n",
      "student__share_firstgeneration_parents_middleschool     0.5%\n",
      "admissions__act_scores_75th_percentile_writing          2.5%\n",
      "admissions__act_scores_midpoint_writing                 2.5%\n",
      "admissions__act_scores_25th_percentile_writing          2.5%\n",
      "admissions__sat_scores_75th_percentile_writing         11.6%\n",
      "dtype: object\n",
      "...\n",
      "student__demographics_first_generation    96.0%\n",
      "student__share_firstgeneration            96.0%\n",
      "student__demographics_dependent           97.9%\n",
      "student__share_independent_students       97.9%\n",
      "student__demographics_age_entry           99.7%\n",
      "dtype: object\n",
      "\n",
      "After imputing using mean:\n",
      "Found 0 features with missing value:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## Filling missing values\n",
    "##################################\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "def percentage(numerator, denomenator):\n",
    "    if type(numerator) == pd.core.series.Series:\n",
    "        return (numerator/denomenator*100).map('{:.1f}%'.format)\n",
    "    \n",
    "    elif type(numerator) == int or type(numerator) == float:\n",
    "        return '{:.1f}%'.format(float(numerator)/float(denomenator)*100)\n",
    "    \n",
    "    else:\n",
    "        print(\"check type\")\n",
    "\n",
    "def DisplayFeatureCompleteness(df):\n",
    "    nums = df.count()\n",
    "    nums = nums[nums < df.shape[0]].sort_values(ascending=True)\n",
    "    print (\"Found %d features with missing value:\\n\" % nums.shape[0])\n",
    "    if (nums.shape[0] > 0):\n",
    "        print (percentage(nums, df.shape[0]).head(5))\n",
    "        print ('...')\n",
    "        print (percentage(nums, df.shape[0]).tail(5))\n",
    "\n",
    "print ('\\nFixing missing values:')\n",
    "DisplayFeatureCompleteness(X)\n",
    "\n",
    "columns = X.columns\n",
    "imputer = Imputer(strategy=impute_strategy)\n",
    "imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "X_score = imputer.transform(X_score)\n",
    "\n",
    "#rearrange DataFrame after transform\n",
    "X = pd.DataFrame(X, columns=columns)\n",
    "X_score = pd.DataFrame(X_score, columns=columns)\n",
    "\n",
    "print ('\\nAfter imputing using ''%s'':' % impute_strategy)\n",
    "DisplayFeatureCompleteness(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features using standard:\n",
      "Sample feature before\n",
      " count    17107.000000\n",
      "mean      5797.635609\n",
      "std       1668.135090\n",
      "min        153.000000\n",
      "25%       5051.500000\n",
      "50%       5797.635609\n",
      "75%       6163.000000\n",
      "max      24892.000000\n",
      "Name: school__faculty_salary, dtype: float64\n",
      "\n",
      "Sample feature after\n",
      " count    1.710700e+04\n",
      "mean    -2.474189e-16\n",
      "std      1.000029e+00\n",
      "min     -3.383899e+00\n",
      "25%     -4.473004e-01\n",
      "50%     -5.452324e-16\n",
      "75%      2.190321e-01\n",
      "max      1.144687e+01\n",
      "Name: school__faculty_salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## Scaling Features\n",
    "##################################\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def StandardScaler(x):\n",
    "    # create scaler\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    #scale feature\n",
    "    x_scale = scaler.fit_transform(x)\n",
    "    return x_scale, scaler\n",
    "\n",
    "def RobustScaler(x):\n",
    "    # create scaler\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    #scale feature\n",
    "    x_scale = scaler.fit_transform(x)\n",
    "    return x_scale, scaler\n",
    "\n",
    "print ('\\nScaling features using %s:' % scaling_method)\n",
    "print ('Sample feature before\\n', X['school__faculty_salary'].describe())\n",
    "\n",
    "if (scaling_method == 'standard'):\n",
    "    X, scaler = StandardScaler(X)\n",
    "else:\n",
    "    X, scaler = RobustScaler(X)\n",
    "\n",
    "X_score = scaler.transform(X_score)\n",
    "\n",
    "#rearrange DataFrame after transform\n",
    "X = pd.DataFrame(X, columns=columns)\n",
    "X_score = pd.DataFrame(X_score, columns=columns)\n",
    "\n",
    "print ('\\nSample feature after\\n', X['school__faculty_salary'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 4 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed: 53.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ExtraTrees:\n",
      "Best Score: -12.7395213783\n",
      "Best Params: {'max_features': 0.5, 'n_estimators': 500}\n",
      "Root of Mean squared error: 0.07\n",
      "Variance score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y = Y['income']\n",
    "\n",
    "param_grid = {\"n_estimators\":[500],\n",
    "              \"max_features\": np.linspace(0.5,1.0,4)\n",
    "             }\n",
    "extraEstimator = ExtraTreesRegressor()\n",
    "\n",
    "\n",
    "grid = GridSearchCV(extraEstimator, param_grid,n_jobs=-1, cv=8, scoring='neg_mean_squared_error', verbose=4)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('Using ExtraTrees:')\n",
    "print('Best Score:', grid.best_score_) \n",
    "print('Best Params:', grid.best_params_) \n",
    "\n",
    "y_pred = grid.predict(X)\n",
    "print(\"Root of Mean squared error: %.2f\"\n",
    "      % math.sqrt(mean_squared_error(y, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y, y_pred))\n",
    "\n",
    "test_results = grid.predict(X_score)\n",
    "\n",
    "T = pd.DataFrame(test_results)\n",
    "T.columns = ['income']\n",
    "T.to_csv('results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### BEST SO FAR\n",
    "\n",
    "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
    "          max_features=0.5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "          min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "          \n",
    "Using ExtraTrees:\n",
    "Best Score: -12.7064558884\n",
    "Best Params: {'max_features': 0.5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
    "Root of Mean squared error: 0.07\n",
    "Variance score: 1.00\n",
    "\n",
    "### Next Step: do Feature reduction and test with current parameters and Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "bestmodel = ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None, max_features=0.5, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "y = Y['income']\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "rfecv = RFECV(estimator=bestmodel, step=10, n_jobs=-1, verbose=4, cv=8,\n",
    "              scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"Number of features selected\")\n",
    "ax.set_ylabel(\"Cross validation score (neg_mean_squared_error)\")\n",
    "ax.set_xlim(380,0)\n",
    "x = range(20,385,5)\n",
    "\n",
    "ax.plot(x, rfecv.grid_scores_[4:])\n",
    "\n",
    "xmax = 330\n",
    "ymax = max(rfecv.grid_scores_)\n",
    "ax.annotate('Max Score: 330', xy=(xmax, ymax), xytext=(xmax, ymax-1),\n",
    "            arrowprops=dict(facecolor='green', shrink=0.1),\n",
    "            )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = pd.DataFrame()\n",
    "F['features'] = X.columns\n",
    "F['ranking'] = rfecv.ranking_\n",
    "F['important'] = rfecv.get_support()\n",
    "\n",
    "# save features for later if we want to reuse it without running RFECV\n",
    "F[F['important'] == True].to_csv('important_features.csv')\n",
    "\n",
    "test_results = rfecv.predict(X_score)\n",
    "T = pd.DataFrame(test_results)\n",
    "T.columns = ['income']\n",
    "T.to_csv('results_with_RFECV_before_hyper.csv')\n",
    "\n",
    "# Put the best features into new df X_new\n",
    "X_new = rfecv.transform(X)\n",
    "X_score_new = rfecv.transform(X_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun estimator on top of X_new\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "param_grid = {\"n_estimators\":[500],\n",
    "              \"max_features\": np.linspace(0.5,1.0,4)\n",
    "             }\n",
    "\n",
    "extraEstimator = ExtraTreesRegressor()\n",
    "\n",
    "grid = GridSearchCV(extraEstimator, param_grid,n_jobs=-1, cv=8, scoring='neg_mean_squared_error', verbose=4)\n",
    "grid.fit(X_new, y)\n",
    "\n",
    "print('Using ExtraTrees After Feature Reduction:')\n",
    "print('Best Score:', grid.best_score_) \n",
    "print('Best Params:', grid.best_params_) \n",
    "\n",
    "y_pred = grid.predict(X_new)\n",
    "print(\"Root of Mean squared error: %.2f\"\n",
    "      % math.sqrt(mean_squared_error(y, y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y, y_pred))\n",
    "\n",
    "test_results = grid.predict(X_score_new)\n",
    "\n",
    "T = pd.DataFrame(test_results)\n",
    "T.columns = ['income']\n",
    "T.to_csv('results_with_RFECV_after_hyper.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
