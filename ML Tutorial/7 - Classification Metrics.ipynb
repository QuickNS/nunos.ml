{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A complete example on classification and further analysis of metrics\n",
    "\n",
    "Loading a dataset concerning the classification of breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thickness</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>chromatin</th>\n",
       "      <th>nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thickness  size  shape  adhesion  epithelial  nuclei  chromatin  nucleoli  \\\n",
       "0          5     1      1         1           2     1.0          3         1   \n",
       "1          5     4      4         5           7    10.0          3         2   \n",
       "2          3     1      1         1           2     2.0          3         1   \n",
       "3          6     8      8         1           3     4.0          3         7   \n",
       "4          4     1      1         3           2     1.0          3         1   \n",
       "\n",
       "   mitoses  status  \n",
       "0        1       2  \n",
       "1        1       2  \n",
       "2        1       2  \n",
       "3        1       2  \n",
       "4        1       2  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#reading data. Notice NaN are encoded as '?' on the dataset so we deal with it during load\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None, na_values='?')\n",
    "\n",
    "cols = ['id','thickness', 'size', 'shape', 'adhesion', 'epithelial', 'nuclei', 'chromatin', 'nucleoli', 'mitoses', 'status']\n",
    "df.columns = cols\n",
    "df = df.drop('id',axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking existence of nans:  True\n",
      "     thickness  size  shape  adhesion  epithelial  nuclei  chromatin  \\\n",
      "23           8     4      5         1           2     NaN          7   \n",
      "40           6     6      6         9           6     NaN          7   \n",
      "139          1     1      1         1           1     NaN          2   \n",
      "145          1     1      3         1           2     NaN          2   \n",
      "158          1     1      2         1           3     NaN          1   \n",
      "164          5     1      1         1           2     NaN          3   \n",
      "235          3     1      4         1           2     NaN          3   \n",
      "249          3     1      1         1           2     NaN          3   \n",
      "275          3     1      3         1           2     NaN          2   \n",
      "292          8     8      8         1           2     NaN          6   \n",
      "294          1     1      1         1           2     NaN          2   \n",
      "297          5     4      3         1           2     NaN          2   \n",
      "315          4     6      5         6           7     NaN          4   \n",
      "321          3     1      1         1           2     NaN          3   \n",
      "411          1     1      1         1           1     NaN          2   \n",
      "617          1     1      1         1           1     NaN          1   \n",
      "\n",
      "     nucleoli  mitoses  status  \n",
      "23          3        1       4  \n",
      "40          8        1       2  \n",
      "139         1        1       2  \n",
      "145         1        1       2  \n",
      "158         1        1       2  \n",
      "164         1        1       2  \n",
      "235         1        1       2  \n",
      "249         1        1       2  \n",
      "275         1        1       2  \n",
      "292        10        1       4  \n",
      "294         1        1       2  \n",
      "297         3        1       2  \n",
      "315         9        1       2  \n",
      "321         1        1       2  \n",
      "411         1        1       2  \n",
      "617         1        1       2  \n",
      "\n",
      "\n",
      "1.0     402\n",
      "10.0    132\n",
      "5.0      30\n",
      "2.0      30\n",
      "3.0      28\n",
      "8.0      21\n",
      "4.0      19\n",
      "9.0       9\n",
      "7.0       8\n",
      "6.0       4\n",
      "Name: nuclei, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking existence of nans: \", df.isnull().values.any())\n",
    "print(df[df.isnull().values])\n",
    "print(\"\\n\")\n",
    "print(df.nuclei.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000     402\n",
      "10.000000    132\n",
      "5.000000      30\n",
      "2.000000      30\n",
      "3.000000      28\n",
      "8.000000      21\n",
      "4.000000      19\n",
      "3.544656      16\n",
      "9.000000       9\n",
      "7.000000       8\n",
      "6.000000       4\n",
      "Name: nuclei, dtype: int64\n",
      "\n",
      "Checking for nans: False\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(df.mean())\n",
    "\n",
    "print(df.nuclei.value_counts())\n",
    "\n",
    "print(\"\\nChecking for nans:\", df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "(419, 9)\n",
      "(419,)\n",
      "\n",
      "\n",
      "Test Data\n",
      "(280, 9)\n",
      "(280,)\n"
     ]
    }
   ],
   "source": [
    "y = df[\"status\"]\n",
    "X = df.drop(\"status\", axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=7)\n",
    "\n",
    "print(\"Training Data\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Test Data\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464285714285714"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score against the test dataset\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class\n",
    "\n",
    "Classification values:\n",
    "- 2 means benign\n",
    "- 4 means malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    183\n",
      "4     97\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.653571\n",
       "Name: status, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [4 2 2 2 4 2 2 4 2 4 2 2 2 2 4 2 2 2 4 2 2 2 4 4 2]\n",
      "Pred: [4 2 2 2 4 2 4 4 2 4 2 2 2 2 4 2 2 2 4 2 2 2 2 4 2]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this case we are predicting as malignant an actually benign tumor -> that is better than the alternative\n",
      "True: 2\n",
      "Pred: 4\n"
     ]
    }
   ],
   "source": [
    "print ('In this case we are predicting as malignant an actually benign tumor -> that is better than the alternative')\n",
    "print ('True:', y_test.values[6])\n",
    "print ('Pred:', y_pred_class[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175   8]\n",
      " [  7  90]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print (confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the matrix\n",
    "\n",
    "- Negative is a benign tumor (coded as 2)\n",
    "- Positive is a malignant tumor (coded as 4)\n",
    "- Rows represent the truth\n",
    "- Columns are the predictions\n",
    "- Every observation in the testing set is represented in exactly one box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Negatives:  183  must be equal to:  183\n",
      "Actual Positives:  97  must be equal to:  97\n",
      "Predicted Negatives:  182  must be equal to:  182\n",
      "Predicted Positives:  98  must be equal to:  98\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Negatives: \", confusion[0,0] + confusion[0,1], \" must be equal to: \", len(y_test[y_test == 2]))\n",
    "print(\"Actual Positives: \", confusion[1,0] + confusion[1,1], \" must be equal to: \", len(y_test[y_test == 4]))\n",
    "\n",
    "print(\"Predicted Negatives: \", confusion[0,0] + confusion[1,0], \" must be equal to: \", len(y_pred_class[y_pred_class == 2]))\n",
    "print(\"Predicted Positives: \", confusion[0,1] + confusion[1,1], \" must be equal to: \", len(y_pred_class[y_pred_class == 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion matrix](images/confusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946428571429\n",
      "0.946428571429\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0535714285714\n",
      "0.0535714285714\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927835051546\n",
      "0.927835051546\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class, pos_label=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956284153005\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0437158469945\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918367346939\n",
      "0.918367346939\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class, pos_label=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**\n",
    "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
