{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ndl.nn import NeuralNetwork\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the XOR dataet\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] epoch=1, loss=0.5115889\n",
      "[INFO] epoch=1000, loss=0.0132142\n",
      "[INFO] epoch=2000, loss=0.0038224\n",
      "[INFO] epoch=3000, loss=0.0020450\n",
      "[INFO] epoch=4000, loss=0.0013505\n",
      "[INFO] epoch=5000, loss=0.0009929\n",
      "[INFO] epoch=6000, loss=0.0007787\n",
      "[INFO] epoch=7000, loss=0.0006375\n",
      "[INFO] epoch=8000, loss=0.0005380\n",
      "[INFO] epoch=9000, loss=0.0004644\n",
      "[INFO] epoch=10000, loss=0.0004079\n",
      "[INFO] epoch=11000, loss=0.0003632\n",
      "[INFO] epoch=12000, loss=0.0003272\n",
      "[INFO] epoch=13000, loss=0.0002974\n",
      "[INFO] epoch=14000, loss=0.0002725\n",
      "[INFO] epoch=15000, loss=0.0002513\n",
      "[INFO] epoch=16000, loss=0.0002331\n",
      "[INFO] epoch=17000, loss=0.0002173\n",
      "[INFO] epoch=18000, loss=0.0002035\n",
      "[INFO] epoch=19000, loss=0.0001913\n",
      "[INFO] epoch=20000, loss=0.0001804\n",
      "[INFO] epoch=21000, loss=0.0001707\n",
      "[INFO] epoch=22000, loss=0.0001620\n",
      "[INFO] epoch=23000, loss=0.0001541\n",
      "[INFO] epoch=24000, loss=0.0001469\n",
      "[INFO] epoch=25000, loss=0.0001403\n"
     ]
    }
   ],
   "source": [
    "# creat a 2-2-1 neural network and train it \n",
    "nn = NeuralNetwork([2, 2, 1], alpha=0.5)\n",
    "# displayUpdate controls the verbosity of the training algorithm\n",
    "nn.fit(X, y, epochs=25000, displayUpdate=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function decreases to aproximately zero over the course of traning using backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=[0 0], truth=0, pred=0.0084, step=0\n",
      "data=[0 1], truth=1, pred=0.9911, step=1\n",
      "data=[1 0], truth=1, pred=0.9909, step=1\n",
      "data=[1 1], truth=0, pred=0.0070, step=0\n"
     ]
    }
   ],
   "source": [
    "# now that our NeuralNetwork is trained, loop over the data points\n",
    "for (x, target) in zip(X, y):\n",
    "    pred = nn.predict(x)[0][0]\n",
    "    step = 1 if pred > 0.5 else 0\n",
    "    print(\"data={}, truth={}, pred={:.4f}, step={}\".format(x, target[0], pred, step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network correctly models the XOR function, thus proving a multi-layer network is capable of learning nonlinear functions.\n",
    "\n",
    "We can also test our hypothesis by removing the hidden layer and see that we can no longer solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] epoch=1, loss=0.5730818\n",
      "[INFO] epoch=1000, loss=0.5007938\n",
      "[INFO] epoch=2000, loss=0.5007938\n",
      "[INFO] epoch=3000, loss=0.5007938\n",
      "[INFO] epoch=4000, loss=0.5007938\n",
      "[INFO] epoch=5000, loss=0.5007938\n",
      "[INFO] epoch=6000, loss=0.5007938\n",
      "[INFO] epoch=7000, loss=0.5007938\n",
      "[INFO] epoch=8000, loss=0.5007938\n",
      "[INFO] epoch=9000, loss=0.5007938\n",
      "[INFO] epoch=10000, loss=0.5007938\n",
      "[INFO] epoch=11000, loss=0.5007938\n",
      "[INFO] epoch=12000, loss=0.5007938\n",
      "[INFO] epoch=13000, loss=0.5007938\n",
      "[INFO] epoch=14000, loss=0.5007938\n",
      "[INFO] epoch=15000, loss=0.5007938\n",
      "[INFO] epoch=16000, loss=0.5007938\n",
      "[INFO] epoch=17000, loss=0.5007938\n",
      "[INFO] epoch=18000, loss=0.5007938\n",
      "[INFO] epoch=19000, loss=0.5007938\n",
      "[INFO] epoch=20000, loss=0.5007938\n",
      "[INFO] epoch=21000, loss=0.5007938\n",
      "[INFO] epoch=22000, loss=0.5007938\n",
      "[INFO] epoch=23000, loss=0.5007938\n",
      "[INFO] epoch=24000, loss=0.5007938\n",
      "[INFO] epoch=25000, loss=0.5007938\n"
     ]
    }
   ],
   "source": [
    "# creat a 2-2-1 neural network and train it \n",
    "nn = NeuralNetwork([2, 1], alpha=0.5)\n",
    "# displayUpdate controls the verbosity of the training algorithm\n",
    "nn.fit(X, y, epochs=25000, displayUpdate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=[0 0], truth=0, pred=0.5161, step=1\n",
      "data=[0 1], truth=1, pred=0.5000, step=1\n",
      "data=[1 0], truth=1, pred=0.4839, step=0\n",
      "data=[1 1], truth=0, pred=0.4678, step=0\n"
     ]
    }
   ],
   "source": [
    "# now that our NeuralNetwork is trained, loop over the data points\n",
    "for (x, target) in zip(X, y):\n",
    "    pred = nn.predict(x)[0][0]\n",
    "    step = 1 if pred > 0.5 else 0\n",
    "    print(\"data={}, truth={}, pred={:.4f}, step={}\".format(x, target[0], pred, step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how much you fiddle with the learning rate or weight initializations, you’ll never\n",
    "be able to approximate the XOR function. This fact is why multi-layer networks with nonlinear\n",
    "activation functions trained via backpropagation are so important – they enable us to learn patterns\n",
    "in datasets that are otherwise nonlinearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
